{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-misc\n",
      "  Downloading scikit_misc-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.8 MB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.22.3\n",
      "  Downloading numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.5 MB 9.4 MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: numpy, scikit-misc\n",
      "\u001b[33m  WARNING: The scripts f2py and numpy-config are installed in '/home/c01teaf/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.7.1 requires numpy<1.23.0,>=1.16.5, but you have numpy 2.0.2 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-2.0.2 scikit-misc-0.3.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting numpy==1.22.0\n",
      "  Downloading numpy-1.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.8 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikit-misc 0.3.1 requires numpy>=1.22.3, but you have numpy 1.22.0 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.22.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3.9 -m pip install --user scikit-misc\n",
    "!python3.9 -m pip install numpy==1.22.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1665\n",
      "1639\n"
     ]
    }
   ],
   "source": [
    "# path1 = '/groups/NovaSeq-02/bioinformatics/users/project_prisyn/Human_TFs_Lambert.txt'\n",
    "# path2 = '/groups/NovaSeq-02/bioinformatics/users/project_prisyn/Human_TFs_AnimalTFDB.txt'\n",
    "\n",
    "path1 = '../data/raw/Human_TFs_Lambert.txt'\n",
    "path2 = '../data/raw/Homo_sapiens_TF.csv'\n",
    "\n",
    "with open(path1, \"r\") as f1:\n",
    "    Human_TFs_Lambert = [line.strip() for line in f1]\n",
    "    \n",
    "Human_TFs_AnimalTFDB = []\n",
    "with open(path2, \"r\") as f:\n",
    "\n",
    "    next(f) \n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) >= 3:\n",
    "            ensembl_id = parts[1]\n",
    "            if ensembl_id:  \n",
    "                Human_TFs_AnimalTFDB.append(ensembl_id)\n",
    "\n",
    "print(len(Human_TFs_AnimalTFDB))\n",
    "print(len(Human_TFs_Lambert)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1508 common genes\n"
     ]
    }
   ],
   "source": [
    "Human_TFs_AnimalTFDB_set = set(Human_TFs_AnimalTFDB)\n",
    "Human_TFs_Lambert_set = set(Human_TFs_Lambert)\n",
    "\n",
    "common_genes = Human_TFs_AnimalTFDB_set.intersection(Human_TFs_Lambert_set)\n",
    "print(f\"Found {len(common_genes)} common genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 genes not common in both sets\n"
     ]
    }
   ],
   "source": [
    "not_common_genes = Human_TFs_AnimalTFDB_set.symmetric_difference(Human_TFs_Lambert_set)\n",
    "print(f\"Found {len(not_common_genes)} genes not common in both sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique to AnimalTFDB: {'GON4L', 'CDIP1', 'ZNF559-ZNF177', 'SMAD2', 'CCDC88A', 'MTA2', 'DMRTC1B', 'PLEK', 'TAX1BP1', 'AC005324.4', 'SSRP1', 'CNBP', 'GABPB2', 'AC010616.1', 'BCLAF1', 'PMS1', 'KIAA1549', 'NCOR1', 'MAEL', 'HMGB1', 'NCOR2', 'AC105001.2', 'PIAS2', 'PIAS4', 'GATAD1', 'LITAF', 'CSDC2', 'RFXANK', 'AC004080.3', 'CREBRF', 'RERE', 'HMGB4', 'MAF1', 'CAPN15', 'JARID2', 'ARID1B', 'DUXB', 'SMAD6', 'TULP3', 'UBTFL1', 'TADA2A', 'MIER1', 'ZMIZ1', 'PAXBP1', 'MIER3', 'PIAS1', 'TFAM', 'TULP1', 'HOPX', 'TULP2', 'RCOR2', 'ZNF622', 'AL033529.1', 'CBFB', 'SMAD7', 'HMGB3', 'HMGXB4', 'AC187653.1', 'RCOR1', 'AC010487.3', 'AC073111.5', 'AC073612.1', 'AC067968.1', 'AC020909.1', 'KMT2C', 'NR0B2', 'ARID4B', 'MYEF2', 'TSC22D2', 'ZNFX1', 'AC092329.3', 'AC019117.3', 'AFF2', 'DNAJC1', 'ARID1A', 'HMGB2', 'PRDM11', 'WDHD1', 'AFF3', 'TOX', 'ID4', 'TBXT', 'AC115220.1', 'ELMSAN1', 'LRRFIP1', 'KLF18', 'AC073111.3', 'AC022167.5', 'ZMIZ2', 'SFPQ', 'ID2', 'SUB1', 'AC010422.6', 'TCF25', 'TSC22D3', 'DMRTC1', 'AC025287.4', 'LYAR', 'MTA3', 'TADA2B', 'SMARCC1', 'TSC22D4', 'SMARCE1', 'DNAJC2', 'HSFX4', 'NSD2', 'PHTF1', 'KHSRP', 'CARHSP1', 'CIZ1', 'MIS18BP1', 'TUB', 'PARP12', 'GCFC2', 'AC118549', 'LRRFIP2', 'TOX3', 'TOX4', 'SMARCAL1', 'NFRKB', 'PBRM1', 'GABPB1', 'YEATS4', 'AFF4', 'ARID4A', 'ZNF720', 'HSFX3', 'SMARCC2', 'CPHXL', 'TOX2', 'AC008770.2', 'CSDE1', 'BHMG1', 'MTA1', 'ZFP91-CNTF', 'AC008758.1', 'ZFP36L2', 'ANKRD30A', 'MLLT10', 'RCOR3', 'HMGXB3', 'AC002310.5', 'AFF1', 'SAMD11', 'ZNF723', 'UBTF', 'PIAS3', 'TFB1M', 'ZFP36L1', 'AC012531.3', 'SMARCA1', 'ID3', 'TULP4', 'BLZF1', 'PHB', 'TCF19', 'ID1'} genes\n",
      "Unique to Lambert: {'SKIL', 'AHDC1', 'FLYWCH1', 'SNAPC2', 'ZNF428', 'ARHGAP35', 'TBP', 'ZNF474', 'TCF20', 'PA2G4', 'ANKZF1', 'MBNL2', 'SAFB2', 'ZNF830', 'ZMAT1', 'ZNF346', 'DPF1', 'DUX3', 'CBX2', 'KDM2B', 'CXXC4', 'SPEN', 'KDM2A', 'FBXL19', 'ASH1L', 'AKAP8', 'TIGD3', 'TIGD5', 'JRKL', 'PRMT3', 'PCGF6', 'CHAMP1', 'ZZZ3', 'ZNF703', 'TET3', 'CPXCR1', 'DPF3', 'ZC3H8', 'KDM5B', 'T', 'PHF20', 'ZBTB9', 'HMGN3', 'POU2AF1', 'ZNF645', 'KAT7', 'ZUFSP', 'MBD6', 'PCGF2', 'TRAFD1', 'GTF2B', 'ZNF385D', 'BRF2', 'ZMAT4', 'PHF19', 'SKOR1', 'AEBP1', 'SMYD3', 'PRR12', 'CXXC1', 'CCDC17', 'MSANTD1', 'ZBED9', 'TBPL1', 'MSANTD4', 'ZNF843', 'MTERF4', 'DOT1L', 'NCOA3', 'ZNF598', 'RBSN', 'SAFB', 'PIN1', 'DNTTIP1', 'PHF1', 'GLYR1', 'TIGD2', 'DNMT1', 'SKOR2', 'KIN', 'ZNF804A', 'SKI', 'MTERF2', 'SNAPC5', 'DZIP1', 'CXXC5', 'JRK', 'MSANTD3', 'TIGD6', 'KCNIP3', 'EEA1', 'AKAP8L', 'MTF2', 'DR1', 'CENPBD1', 'CGGBP1', 'LIN54', 'KCMF1', 'CHCHD3', 'KMT2B', 'NCOA2', 'POGK', 'ZNF385C', 'FAM200B', 'SCMH1', 'SRCAP', 'MTERF3', 'MYPOP', 'PHF21A', 'MTERF1', 'NACC2', 'CENPB', 'SCML4', 'ZNF804B', 'DRAP1', 'SGSM2', 'TET1', 'TBPL2', 'TOPORS', 'ZNF365', 'BPTF', 'REXO4', 'KMT2A', 'AC008770.3', 'NAIF1', 'NFE4', 'DUX1', 'TIGD4', 'TIGD7', 'TIGD1', 'ZNF451'} genes\n"
     ]
    }
   ],
   "source": [
    "unique_to_AnimalTFDB = Human_TFs_AnimalTFDB_set - Human_TFs_Lambert_set\n",
    "unique_to_Lambert = Human_TFs_Lambert_set - Human_TFs_AnimalTFDB_set\n",
    "\n",
    "print(f\"Unique to AnimalTFDB: {(unique_to_AnimalTFDB)} genes\")\n",
    "print(f\"Unique to Lambert: {(unique_to_Lambert)} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID dataset - haniffa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc \n",
    "import numpy as np \n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adata(file_path):\n",
    "    adata = sc.read_h5ad(file_path)\n",
    "    return adata \n",
    "\n",
    "def map_disease_labels(adata, label_column, encoder_column): \n",
    "    encoder = LabelEncoder()  # Create a single instance of LabelEncoder \n",
    "    adata.obs[encoder_column] = encoder.fit_transform(adata.obs[label_column].values)  # Transform labels \n",
    "    mapping_disease_label = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))  # Store mapping \n",
    "    return adata, mapping_disease_label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haniffa21.max_patient.h5ad  haniffa21.processed.h5ad  preprocessing_covid.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data/raw/COVID_Haniffa21/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"/groups/NovaSeq-02/bioinformatics/users/project_prisyn/haniffa_covid.h5ad\" \n",
    "path = r\"../data/raw/COVID_Haniffa21/haniffa21.processed.h5ad\" \n",
    "adata_covid = load_adata(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_mask = adata_covid.var['feature_types'] == 'Gene Expression' \n",
    "adata_rna = adata_covid[:, gene_mask] \n",
    "adata_covid_binary = adata_rna[adata_rna.obs['Status'].isin(['Covid', 'Healthy'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 624325 × 24737\n",
       "    obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'\n",
       "    var: 'feature_types'\n",
       "    uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'\n",
       "    obsm: 'X_pca', 'X_pca_harmony', 'X_umap'\n",
       "    layers: 'raw'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_covid_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_covid_binary.obsm \n",
    "del adata_covid_binary.uns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 624325 × 24737\n",
       "    obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'\n",
       "    var: 'feature_types'\n",
       "    layers: 'raw'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_covid_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_covid_binary, mapping_disease_label_covid_binary = map_disease_labels(adata=adata_covid_binary, \n",
    "                                                                            label_column='Status', \n",
    "                                                                            encoder_column='disease_label_binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease_label_binary\n",
      "0    90\n",
      "1    23\n",
      "Name: patient_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(adata_covid_binary.obs.groupby('disease_label_binary', observed=True)['patient_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_covid_binary.layers['preprocessed']= adata_covid_binary.X.copy()  # Save the preprocessed data in a new layer \n",
    "adata_covid_binary.layers['raw_counts'] = adata_covid_binary.layers['raw'].copy() # saving raw counts and using it for  preprocessing \n",
    "adata_covid_binary.X = adata_covid_binary.layers['raw_counts'].copy() \n",
    "adata_covid_binary.var[\"mt\"] = adata_covid_binary.var_names.str.startswith(\"MT-\") \n",
    "adata_covid_binary.var[\"ribo\"] = adata_covid_binary.var_names.str.startswith((\"RPS\", \"RPL\")) \n",
    "adata_covid_binary.var[\"hb\"] = adata_covid_binary.var_names.str.contains(\"^HB[^(P)]\") \n",
    "sc.pp.calculate_qc_metrics(adata_covid_binary, qc_vars=[\"mt\", \"ribo\", \"hb\"], inplace=True, log1p=False) \n",
    "sc.pp.filter_cells(adata_covid_binary, min_genes=200) \n",
    "sc.pp.filter_genes(adata_covid_binary, min_cells=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = adata_covid_binary.obs['patient_id'].unique()\n",
    "adata_list = [adata_covid_binary[adata_covid_binary.obs['patient_id'] == pid].copy() for pid in patient_ids] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes expressed in all patients: 12087\n"
     ]
    }
   ],
   "source": [
    "# For each patient, get set of expressed genes (expressed in ≥1 cell)\n",
    "expressed_genes_per_patient = []\n",
    "for ad in adata_list:\n",
    "    if hasattr(ad.X, \"toarray\"):\n",
    "        expr = ad.X.toarray()\n",
    "    else:\n",
    "        expr = ad.X \n",
    "    gene_sum = expr.sum(axis=0)\n",
    "    genes_expressed = set(ad.var_names[gene_sum > 0])\n",
    "    expressed_genes_per_patient.append(genes_expressed)\n",
    "\n",
    "# Intersection across all patients\n",
    "common_genes = set.intersection(*expressed_genes_per_patient)\n",
    "print(f\"Number of genes expressed in all patients: {len(common_genes)}\")\n",
    "\n",
    "for i, ad in enumerate(adata_list):\n",
    "    genes_to_keep = ad.var_names.isin(common_genes)\n",
    "    adata_list[i] = ad[:, genes_to_keep].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_list_filtered = [ad for ad in adata_list if ad.n_obs >= 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --user scikit-misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in adata_list_filtered:\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4, inplace=True)\n",
    "    sc.pp.log1p(adata) \n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat_v3', layer='raw_counts') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LINC00115      True\n",
       "NOC2L         False\n",
       "KLHL17        False\n",
       "PLEKHN1       False\n",
       "HES4           True\n",
       "              ...  \n",
       "MT-ND4        False\n",
       "MT-ND5        False\n",
       "MT-ND6         True\n",
       "MT-CYB        False\n",
       "AC240274.1    False\n",
       "Name: highly_variable, Length: 12087, dtype: bool"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8205, 2000)\n",
      "(5655, 2000)\n",
      "(10295, 2000)\n",
      "(10446, 2000)\n",
      "(9019, 2000)\n",
      "(7128, 2000)\n",
      "(10207, 2000)\n",
      "(6847, 2000)\n",
      "(1190, 2000)\n",
      "(6149, 2000)\n",
      "(6029, 2000)\n",
      "(8819, 2000)\n",
      "(3261, 2000)\n",
      "(7585, 2000)\n",
      "(7985, 2000)\n",
      "(6808, 2000)\n",
      "(10082, 2000)\n",
      "(11710, 2000)\n",
      "(10084, 2000)\n",
      "(12081, 2000)\n",
      "(8004, 2000)\n",
      "(5505, 2000)\n",
      "(2096, 2000)\n",
      "(7816, 2000)\n",
      "(5096, 2000)\n",
      "(9608, 2000)\n",
      "(9542, 2000)\n",
      "(8232, 2000)\n",
      "(10014, 2000)\n",
      "(8244, 2000)\n",
      "(7605, 2000)\n",
      "(6388, 2000)\n",
      "(6614, 2000)\n",
      "(7300, 2000)\n",
      "(7953, 2000)\n",
      "(7100, 2000)\n",
      "(7010, 2000)\n",
      "(7016, 2000)\n",
      "(2223, 2000)\n",
      "(3217, 2000)\n",
      "(8530, 2000)\n",
      "(4316, 2000)\n",
      "(9083, 2000)\n",
      "(8111, 2000)\n",
      "(5848, 2000)\n",
      "(8639, 2000)\n",
      "(14317, 2000)\n",
      "(7011, 2000)\n",
      "(8182, 2000)\n",
      "(8371, 2000)\n",
      "(8919, 2000)\n",
      "(6932, 2000)\n",
      "(7987, 2000)\n",
      "(9458, 2000)\n",
      "(6896, 2000)\n",
      "(5589, 2000)\n",
      "(3101, 2000)\n",
      "(14086, 2000)\n",
      "(8574, 2000)\n",
      "(4494, 2000)\n",
      "(3616, 2000)\n",
      "(4760, 2000)\n",
      "(7446, 2000)\n",
      "(3815, 2000)\n",
      "(10921, 2000)\n",
      "(8511, 2000)\n",
      "(6853, 2000)\n",
      "(2727, 2000)\n",
      "(3884, 2000)\n",
      "(4951, 2000)\n",
      "(2626, 2000)\n",
      "(3219, 2000)\n",
      "(5731, 2000)\n",
      "(2233, 2000)\n",
      "(1522, 2000)\n",
      "(1184, 2000)\n",
      "(3431, 2000)\n",
      "(2812, 2000)\n",
      "(3038, 2000)\n",
      "(1905, 2000)\n",
      "(2614, 2000)\n",
      "(1466, 2000)\n",
      "(2040, 2000)\n",
      "(4259, 2000)\n",
      "(1757, 2000)\n",
      "(4164, 2000)\n",
      "(2576, 2000)\n",
      "(2497, 2000)\n",
      "(5427, 2000)\n",
      "(2647, 2000)\n",
      "(1361, 2000)\n",
      "(1431, 2000)\n",
      "(2674, 2000)\n",
      "(1940, 2000)\n",
      "(3810, 2000)\n",
      "(2720, 2000)\n",
      "(5492, 2000)\n",
      "(2924, 2000)\n",
      "(4317, 2000)\n",
      "(2463, 2000)\n",
      "(1661, 2000)\n",
      "(1719, 2000)\n",
      "(2348, 2000)\n",
      "(2568, 2000)\n",
      "(3371, 2000)\n",
      "(1941, 2000)\n",
      "(1168, 2000)\n",
      "(2622, 2000)\n",
      "(3408, 2000)\n",
      "(2958, 2000)\n"
     ]
    }
   ],
   "source": [
    "for i in adata_list_filtered:\n",
    "    print(i.X[:, i.var['highly_variable']].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_1394661/668683560.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata = max(adata_list_filtered, key=lambda ad: ad.n_obs) # all genes \n",
    "max_adata_hvg = max_adata[:, max_adata.var['highly_variable']].copy() # 2000 HVG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata, max_adata_hvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_zero_expression_cells_per_gene(adata):\n",
    "    if hasattr(adata.X, \"toarray\"):\n",
    "        expr_matrix = adata.X.toarray()\n",
    "    else:\n",
    "        expr_matrix = adata.X\n",
    "    zero_counts = (expr_matrix == 0).sum(axis=0)  # zero counts per gene\n",
    "    zero_counts_per_gene = dict(zip(adata.var_names, zero_counts))\n",
    "    return zero_counts_per_gene\n",
    "\n",
    "zero_counts_per_gene = count_zero_expression_cells_per_gene(max_adata_hvg)\n",
    "for gene, zero_count in zero_counts_per_gene.items():\n",
    "    if zero_count > 0:\n",
    "        print(f\"{gene}: {zero_count} cells with zero expression\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.highly_variable_genes(max_adata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(max_adata_hvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(max_adata_hvg, n_pcs=50, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(max_adata_hvg, color=[\"initial_clustering\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(max_adata_hvg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(max_adata_hvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(max_adata_hvg,color=\"initial_clustering\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(max_adata_hvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(max_adata_hvg, color=[\"leiden\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split_adata(adata, label_key='initial_clustering', test_size=1000, val_size=1000, random_state=42):\n",
    "    \"\"\"Split AnnData into train, val, and test with stratification on a label column.\"\"\"\n",
    "    labels = adata.obs[label_key].values\n",
    "    all_idx = np.arange(adata.n_obs)\n",
    "\n",
    "    sss_test = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    train_val_idx, test_idx = next(sss_test.split(all_idx, labels))\n",
    "\n",
    "    sss_val = StratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=random_state)\n",
    "    train_idx, val_idx = next(sss_val.split(train_val_idx, labels[train_val_idx]))\n",
    "    \n",
    "    split = np.array(['train'] * adata.n_obs)\n",
    "    split[test_idx] = 'test'\n",
    "    split[train_val_idx[val_idx]] = 'val'\n",
    "    adata.obs['split'] = split\n",
    "    return adata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_hvg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_hvg = stratified_split_adata(max_adata_hvg, random_state=random_state)\n",
    "\n",
    "# To access subsets:\n",
    "max_adata_hvg_train = max_adata_hvg[max_adata_hvg.obs['split'] == 'train'].copy()\n",
    "max_adata_hvg_val   = max_adata_hvg[max_adata_hvg.obs['split'] == 'val'].copy()\n",
    "max_adata_hvg_test  = max_adata_hvg[max_adata_hvg.obs['split'] == 'test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in [max_adata_hvg_train, max_adata_hvg_val, max_adata_hvg_test]:\n",
    "    sc.pp.pca(adata, n_comps=50)\n",
    "    sc.pp.neighbors(adata)\n",
    "    sc.tl.umap(adata)\n",
    "    sc.pl.umap(adata,color=\"initial_clustering\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_celltype_proportions(adata, split_key='split', label_key='initial_clustering', normalize=False):\n",
    "    crosstab = pd.crosstab(adata.obs[label_key], adata.obs[split_key])\n",
    "    if normalize:\n",
    "        proportions = crosstab.div(crosstab.sum(axis=0), axis=1)\n",
    "        return proportions\n",
    "    else:\n",
    "        return crosstab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Get proportions of cell types across train/val/test\n",
    "proportions_df = compare_celltype_proportions(max_adata_hvg)\n",
    "print(proportions_df)\n",
    "proportions_df.plot(kind='bar', figsize=(10, 5), title=\"Cell Type Proportions Across Splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_hvg = stratified_split_adata(max_adata_hvg, test_size=2000, val_size=2000) #increasing the test and val size to 2000\n",
    "\n",
    "# To access subsets:\n",
    "max_adata_hvg_train_2000 = max_adata_hvg[max_adata_hvg.obs['split'] == 'train'].copy()\n",
    "max_adata_hvg_val_2000   = max_adata_hvg[max_adata_hvg.obs['split'] == 'val'].copy()\n",
    "max_adata_hvg_test_2000  = max_adata_hvg[max_adata_hvg.obs['split'] == 'test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_df = compare_celltype_proportions(max_adata_hvg)\n",
    "print(proportions_df)\n",
    "proportions_df.plot(kind='bar', figsize=(10, 5), title=\"Cell Type Proportions Across Splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting TFs \n",
    "\n",
    "# only for one donor from 2000 genes # Lambert \n",
    "hvg_genes = set(max_adata_hvg.var_names)\n",
    "tfs_in_hvgs = Human_TFs_Lambert_set & hvg_genes # Get intersection of HVGs and TFs\n",
    "print(f\"Number of TFs found in HVGs: {len(tfs_in_hvgs)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_hvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_zero_expression_cells_per_gene(adata):\n",
    "    if hasattr(adata.X, \"toarray\"):\n",
    "        expr_matrix = adata.X.toarray()\n",
    "    else:\n",
    "        expr_matrix = adata.X\n",
    "    zero_counts = (expr_matrix == 0).sum(axis=0)  # zero counts per gene\n",
    "    zero_counts_per_gene = dict(zip(adata.var_names, zero_counts))\n",
    "    return zero_counts_per_gene\n",
    "\n",
    "zero_counts_per_gene = count_zero_expression_cells_per_gene(max_adata_hvg)\n",
    "for gene, zero_count in zero_counts_per_gene.items():\n",
    "    if zero_count > 0:\n",
    "        print(f\"{gene}: {zero_count} cells with zero expression\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split_adata(adata, test_size=1000, val_size=1000, random_state=42):\n",
    "    \"\"\"Randomly split AnnData into train, val, and test (no stratification).\"\"\"\n",
    "    all_idx = np.arange(adata.n_obs)\n",
    "\n",
    "    # Split off test set\n",
    "    ss_test = ShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    train_val_idx, test_idx = next(ss_test.split(all_idx))\n",
    "\n",
    "    # Split remaining into train/val\n",
    "    ss_val = ShuffleSplit(n_splits=1, test_size=val_size, random_state=random_state)\n",
    "    train_idx, val_idx = next(ss_val.split(train_val_idx))\n",
    "\n",
    "    # Initialize split labels\n",
    "    split = np.array(['train'] * adata.n_obs)\n",
    "    split[test_idx] = 'test'\n",
    "    split[train_val_idx[val_idx]] = 'val'\n",
    "\n",
    "    adata.obs['split'] = split\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_hvg_random = random_split_adata(max_adata_hvg, random_state=random_state)\n",
    "\n",
    "# To access subsets:\n",
    "max_adata_hvg_train_random = max_adata_hvg[max_adata_hvg.obs['split'] == 'train'].copy()\n",
    "max_adata_hvg_val_random   = max_adata_hvg[max_adata_hvg.obs['split'] == 'val'].copy()\n",
    "max_adata_hvg_test_random = max_adata_hvg[max_adata_hvg.obs['split'] == 'test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in [max_adata_hvg_train_random, max_adata_hvg_val_random, max_adata_hvg_test_random]:\n",
    "    sc.pp.pca(adata, n_comps=50)\n",
    "    sc.pp.neighbors(adata)\n",
    "    sc.tl.umap(adata)\n",
    "    sc.pl.umap(adata,color=\"initial_clustering\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_df = compare_celltype_proportions(max_adata_hvg_random)\n",
    "print(proportions_df)\n",
    "proportions_df.plot(kind='bar', figsize=(10, 5), title=\"Cell Type Proportions Across Splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../data/processed/COVID_Haniffa21/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=f'../data/processed/COVID_Haniffa21/CrossVal_{random_state}'\n",
    "import os\n",
    "os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_hvg_train_2000.write_h5ad(f'{path}/COVID_Haniffa21_train.h5ad')\n",
    "max_adata_hvg_test_2000.write_h5ad(f'{path}/COVID_Haniffa21_test.h5ad')\n",
    "max_adata_hvg_val_2000.write_h5ad(f'{path}/COVID_Haniffa21_validation.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "random_state=1000\n",
    "path=f'../data/processed/COVID_Haniffa21/CrossVal_{random_state}'\n",
    "max_adata_hvg_train_2000 = sc.read_h5ad(f'{path}/COVID_Haniffa21_train.h5ad')\n",
    "max_adata_hvg_test_2000 = sc.read_h5ad(f'{path}/COVID_Haniffa21_test.h5ad')\n",
    "max_adata_hvg_val_2000 = sc.read_h5ad(f'{path}/COVID_Haniffa21_validation.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(max_adata_hvg_test_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_genes_with_all_zeros(adata):\n",
    "    X_dense = adata.X.todense() if hasattr(adata.X, \"todense\") else adata.X\n",
    "\n",
    "    # Find columns where all entries are zero\n",
    "    all_zero_mask = np.all(X_dense == 0.0, axis=0).tolist()[0]\n",
    "\n",
    "    # Get corresponding gene names\n",
    "    all_zero_genes = adata.to_df().columns[all_zero_mask].tolist()\n",
    "\n",
    "    return all_zero_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_genes_with_all_zeros(max_adata_hvg_train_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_genes_with_all_zeros(max_adata_hvg_test_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_genes_with_all_zeros(max_adata_hvg_val_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_split_dict={'train': max_adata_hvg_train_2000, \n",
    "              'test': max_adata_hvg_test_2000,\n",
    "              'validation': max_adata_hvg_val_2000}\n",
    "\n",
    "for split, max_adata in max_adata_split_dict.items():\n",
    "    zero_expressd_genes = (((max_adata.X.todense()==0).sum(axis=0))==max_adata.shape[0]).sum()\n",
    "    print(f\"{split}: {zero_expressd_genes} genes have zero expression in all cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split in [max_adata_hvg_train, max_adata_hvg_test, max_adata_hvg_val]:\n",
    "#     zero_expressd_gaenes = (((split.X.todense()==0).sum(axis=0))==split.shape[0]).sum()\n",
    "#     print(zero_expressd_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split in [max_adata_hvg_train_random, max_adata_hvg_test_random, max_adata_hvg_val_random]:\n",
    "#     zero_expressd_genes = (((split.X.todense()==0).sum(axis=0))==split.shape[0]).sum()\n",
    "#     print(zero_expressd_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'test', 'validation']:\n",
    "    max_adata_old = sc.read_h5ad(f'../data/processed/COVID_Haniffa21-old/CrossVal_1000/COVID_Haniffa21_{split}.h5ad')\n",
    "    zero_expressd_genes = len(get_genes_with_all_zeros(max_adata_old))\n",
    "    print(f\"{split}: {zero_expressd_genes} genes have zero expression in all cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_hvg_test_2000.obs['initial_clustering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_old.obs['initial_clustering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_hvg_test_2000.obs['initial_clustering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_hvg_test_2000.obs['leiden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_adata_hvg_test_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
